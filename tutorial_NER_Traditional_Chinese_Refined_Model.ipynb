{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "請記得要先將tensorflow更新到最新的版本\n",
    "\n",
    "pip install --upgrade  tensorflow\n",
    "\n",
    "pip install --upgrade  tensorflow-gpu\n",
    "\n",
    "之後再將numpy更新到最新的版本\n",
    "\n",
    "pip install --upgrade  numpy\n",
    "\n",
    "\n",
    "如果第一個cell有numpy的錯誤，請將 numpy unsatll後再安裝最新的版本\n",
    "\n",
    "\n",
    "這是用我們train好的模型，感謝王俊凱大大。模型編號1559725764 在第一個cell的第35行設定\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 4271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Namespace(CRF=True, batch_size=64, clip=5.0, demo_model='1559725764', dropout=0.5, embedding_dim=300, epoch=40, hidden_dim=300, lr=0.001, mode='demo', optimizer='Adam', pretrain_embedding='random', shuffle=True, test_data='data_path', train_data='data_path', update_embedding=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data_path_save\\1559725764\\results\n"
     ]
    }
   ],
   "source": [
    "#接下來串接\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, argparse, time, random\n",
    "from model import BiLSTM_CRF\n",
    "from utils import str2bool, get_logger, get_entity\n",
    "from data import read_corpus, read_dictionary, tag2label, random_embedding, vocab_build\n",
    "\n",
    "## Session configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # default: 0\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2  # need ~700MB GPU memory\n",
    "\n",
    "parser = argparse.ArgumentParser(description='BiLSTM-CRF for Chinese NER task')\n",
    "#parser.add_argument('--update_train_data', type=str, default='data_path', help='update training data set')\n",
    "\n",
    "parser.add_argument('--train_data', type=str, default='data_path', help='train data source')\n",
    "parser.add_argument('--test_data', type=str, default='data_path', help='test data source')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='#sample of each minibatch')\n",
    "parser.add_argument('--epoch', type=int, default=40, help='#epoch of training')#default=40\n",
    "\n",
    "parser.add_argument('--hidden_dim', type=int, default=300, help='#dim of hidden state')\n",
    "parser.add_argument('--optimizer', type=str, default='Adam', help='Adam/Adadelta/Adagrad/RMSProp/Momentum/SGD')\n",
    "parser.add_argument('--CRF', type=str2bool, default=True, help='use CRF at the top layer. if False, use Softmax')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "parser.add_argument('--clip', type=float, default=5.0, help='gradient clipping')\n",
    "parser.add_argument('--dropout', type=float, default=0.5, help='dropout keep_prob')\n",
    "parser.add_argument('--update_embedding', type=str2bool, default=True, help='update embedding during training')\n",
    "parser.add_argument('--pretrain_embedding', type=str, default='random', help='use pretrained char embedding or init it randomly')\n",
    "parser.add_argument('--embedding_dim', type=int, default=300, help='random init char embedding_dim')\n",
    "parser.add_argument('--shuffle', type=str2bool, default=True, help='shuffle training data before each epoch')\n",
    "parser.add_argument('--mode', type=str, default='demo', help='train/test/demo/update')\n",
    "parser.add_argument('--demo_model', type=str, default='1559725764', help='model for test and demo')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "## get char embeddings\n",
    "word2id = read_dictionary(os.path.join('.', args.train_data, 'word2id.pkl'))\n",
    "if args.pretrain_embedding == 'random':\n",
    "    embeddings = random_embedding(word2id, args.embedding_dim)\n",
    "else:\n",
    "    embedding_path = 'pretrain_embedding.npy'\n",
    "    embeddings = np.array(np.load(embedding_path), dtype='float32')\n",
    "\n",
    "\n",
    "train_path = os.path.join('.', args.train_data, 'train_data')\n",
    "test_path = os.path.join('.', args.test_data, 'test_data')\n",
    "train_data = read_corpus(train_path)\n",
    "test_data = read_corpus(test_path); test_size = len(test_data)\n",
    "\n",
    "paths = {}\n",
    "timestamp = str(int(time.time())) if args.mode == 'train' else args.demo_model\n",
    "output_path = os.path.join('.', args.train_data+\"_save\", timestamp)\n",
    "\n",
    "if not os.path.exists(output_path): os.makedirs(output_path)\n",
    "    \n",
    "summary_path = os.path.join(output_path, \"summaries\")\n",
    "paths['summary_path'] = summary_path\n",
    "\n",
    "if not os.path.exists(summary_path): os.makedirs(summary_path)\n",
    "model_path = os.path.join(output_path, \"checkpoints/\")\n",
    "if not os.path.exists(model_path): os.makedirs(model_path)\n",
    "ckpt_prefix = os.path.join(model_path, \"model\")\n",
    "paths['model_path'] = ckpt_prefix\n",
    "\n",
    "result_path = os.path.join(output_path, \"results\")\n",
    "paths['result_path'] = result_path\n",
    "\n",
    "if not os.path.exists(result_path): os.makedirs(result_path)\n",
    "log_path = os.path.join(result_path, \"log.txt\")\n",
    "paths['log_path'] = log_path\n",
    "\n",
    "get_logger(log_path).info(str(args))\n",
    "\n",
    "print(paths['result_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data_path_save\\1559725764\\checkpoints/model-633400\n"
     ]
    }
   ],
   "source": [
    "#讀取該模型的參數\n",
    "ckpt_file = tf.train.latest_checkpoint(model_path)\n",
    "print(ckpt_file)\n",
    "paths['model_path'] = ckpt_file\n",
    "#build_graph 建構一次就可以了\n",
    "tf.reset_default_graph()#如果沒有家這個，會有kernel is already exist的錯誤\n",
    "model = BiLSTM_CRF(args, embeddings, tag2label, word2id, paths, config=config)\n",
    "model.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#這邊就放入你們要找的文章內容\n",
    "article = \"鏡週刊報導油商陳世憲去年違反聯合國禁運，偷偷賣油給北韓，成為台灣首位遭資恐防制法制裁的對象，數億元資產全被凍結，但陳甚至致電至法務部，揚言殺光法務部的政次陳明堂及洗錢防制辦公室檢察官蔡佩玲全家，恐嚇危害執法人員生命。台北地檢署今上午分他字案調查，案由為恐嚇。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "新聞文章內文 : 鏡週刊報導油商陳世憲去年違反聯合國禁運，偷偷賣油給北韓，成為台灣首位遭資恐防制法制裁的對象，數億元資產全被凍結，但陳甚至致電至法務部，揚言殺光法務部的政次陳明堂及洗錢防制辦公室檢察官蔡佩玲全家，恐嚇危害執法人員生命。台北地檢署今上午分他字案調查，案由為恐嚇。\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from .\\data_path_save\\1559725764\\checkpoints/model-633400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring parameters from .\\data_path_save\\1559725764\\checkpoints/model-633400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "分析結果如下:\n",
      "文章出現人名: ['陳世憲', '陳明堂', '蔡佩玲']\n",
      "文章出現地名: ['北韓', '台灣']\n",
      "文章出現組織: ['聯合國', '法務部', '揚言殺光法務部', '洗錢防制辦公室', '台北地檢署']\n"
     ]
    }
   ],
   "source": [
    "print(\"\" )\n",
    "print(\"新聞文章內文 : \" + article)\n",
    "print(\"\" )\n",
    "\n",
    "#下面這段可以重複使用，找出三個entity，看你們要不要把它包成一個function\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    saver.restore(sess, ckpt_file)\n",
    "    demo_sent = article.strip()\n",
    "    demo_data = [(demo_sent, ['O'] * len(demo_sent))]\n",
    "    tag = model.demo_one(sess, demo_data)\n",
    "    PER, LOC, ORG = get_entity(tag, demo_sent)\n",
    "    print(\"\" )\n",
    "    print(\"分析結果如下:\" )\n",
    "    print('文章出現人名: {}\\n文章出現地名: {}\\n文章出現組織: {}'.format(PER, LOC, ORG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是確定存在check point 的variable的結構跟tensorflow內的結構是否依樣，因為如果你們tensorflow版本汰舊的話會有\n",
    "NotFoundError: ..... not found in checkpoint files這類的錯誤，通常是你的tensorflow版本太舊了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_name:  bi-lstm/bidirectional_rnn/bw/lstm_cell/kernel\n",
      "tensor_name:  bi-lstm/bidirectional_rnn/bw/lstm_cell/bias\n",
      "tensor_name:  train_step/proj/W/Adam\n",
      "tensor_name:  bi-lstm/bidirectional_rnn/fw/lstm_cell/kernel\n",
      "tensor_name:  bi-lstm/bidirectional_rnn/fw/lstm_cell/bias\n",
      "tensor_name:  train_step/bi-lstm/bidirectional_rnn/bw/lstm_cell/kernel/Adam\n",
      "tensor_name:  train_step/bi-lstm/bidirectional_rnn/bw/lstm_cell/bias/Adam\n",
      "tensor_name:  proj/W\n",
      "tensor_name:  train_step/words/_word_embeddings/Adam_1\n",
      "tensor_name:  proj/b\n",
      "tensor_name:  train_step/bi-lstm/bidirectional_rnn/bw/lstm_cell/kernel/Adam_1\n",
      "tensor_name:  train_step/bi-lstm/bidirectional_rnn/bw/lstm_cell/bias/Adam_1\n",
      "tensor_name:  train_step/beta1_power\n",
      "tensor_name:  train_step/beta2_power\n",
      "tensor_name:  train_step/bi-lstm/bidirectional_rnn/fw/lstm_cell/kernel/Adam\n",
      "tensor_name:  train_step/bi-lstm/bidirectional_rnn/fw/lstm_cell/bias/Adam\n",
      "tensor_name:  train_step/bi-lstm/bidirectional_rnn/fw/lstm_cell/kernel/Adam_1\n",
      "tensor_name:  train_step/bi-lstm/bidirectional_rnn/fw/lstm_cell/bias/Adam_1\n",
      "tensor_name:  train_step/global_step\n",
      "tensor_name:  train_step/proj/W/Adam_1\n",
      "tensor_name:  train_step/proj/b/Adam\n",
      "tensor_name:  train_step/proj/b/Adam_1\n",
      "tensor_name:  train_step/transitions/Adam\n",
      "tensor_name:  train_step/transitions/Adam_1\n",
      "tensor_name:  train_step/words/_word_embeddings/Adam\n",
      "tensor_name:  transitions\n",
      "tensor_name:  words/_word_embeddings\n"
     ]
    }
   ],
   "source": [
    "#這裡會把你checkpoint中儲存的模型內的參數結構顯示出來\n",
    "import os\n",
    "from tensorflow.python import pywrap_tensorflow\n",
    "\n",
    "reader = pywrap_tensorflow.NewCheckpointReader(ckpt_file)\n",
    "var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "# Print tensor name and values\n",
    "for key in var_to_shape_map:\n",
    "    print(\"tensor_name: \", key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'words/_word_embeddings:0' shape=(4271, 300) dtype=float32_ref>,\n",
       " <tf.Variable 'bi-lstm/bidirectional_rnn/fw/lstm_cell/kernel:0' shape=(600, 1200) dtype=float32_ref>,\n",
       " <tf.Variable 'bi-lstm/bidirectional_rnn/fw/lstm_cell/bias:0' shape=(1200,) dtype=float32_ref>,\n",
       " <tf.Variable 'bi-lstm/bidirectional_rnn/bw/lstm_cell/kernel:0' shape=(600, 1200) dtype=float32_ref>,\n",
       " <tf.Variable 'bi-lstm/bidirectional_rnn/bw/lstm_cell/bias:0' shape=(1200,) dtype=float32_ref>,\n",
       " <tf.Variable 'proj/W:0' shape=(600, 7) dtype=float32_ref>,\n",
       " <tf.Variable 'proj/b:0' shape=(7,) dtype=float32_ref>,\n",
       " <tf.Variable 'transitions:0' shape=(7, 7) dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/global_step:0' shape=() dtype=int32_ref>,\n",
       " <tf.Variable 'train_step/beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/words/_word_embeddings/Adam:0' shape=(4271, 300) dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/words/_word_embeddings/Adam_1:0' shape=(4271, 300) dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/bi-lstm/bidirectional_rnn/fw/lstm_cell/kernel/Adam:0' shape=(600, 1200) dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/bi-lstm/bidirectional_rnn/fw/lstm_cell/kernel/Adam_1:0' shape=(600, 1200) dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/bi-lstm/bidirectional_rnn/fw/lstm_cell/bias/Adam:0' shape=(1200,) dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/bi-lstm/bidirectional_rnn/fw/lstm_cell/bias/Adam_1:0' shape=(1200,) dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/bi-lstm/bidirectional_rnn/bw/lstm_cell/kernel/Adam:0' shape=(600, 1200) dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/bi-lstm/bidirectional_rnn/bw/lstm_cell/kernel/Adam_1:0' shape=(600, 1200) dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/bi-lstm/bidirectional_rnn/bw/lstm_cell/bias/Adam:0' shape=(1200,) dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/bi-lstm/bidirectional_rnn/bw/lstm_cell/bias/Adam_1:0' shape=(1200,) dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/proj/W/Adam:0' shape=(600, 7) dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/proj/W/Adam_1:0' shape=(600, 7) dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/proj/b/Adam:0' shape=(7,) dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/proj/b/Adam_1:0' shape=(7,) dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/transitions/Adam:0' shape=(7, 7) dtype=float32_ref>,\n",
       " <tf.Variable 'train_step/transitions/Adam_1:0' shape=(7, 7) dtype=float32_ref>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()#這邊則是tensorflow內部的結構，妳可以比對看看是否跟上面的一樣"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
